"""
SM_UP GPU Worker Service
Ø®Ø¯Ù…Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Flux Dev + LoRA
"""

import os
import asyncio
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.responses import JSONResponse
import uvicorn
from loguru import logger

from core.config import settings
from core.models import UpscaleRequest, UpscaleResponse, HealthResponse
from core.upscaler import FluxUpscaler
from core.monitoring import setup_monitoring
from utils.file_handler import FileHandler
from utils.gpu_monitor import GPUMonitor


# Global instances
upscaler = None
file_handler = None
gpu_monitor = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Ø¥Ø¯Ø§Ø±Ø© Ø¯ÙˆØ±Ø© Ø­ÙŠØ§Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"""
    global upscaler, file_handler, gpu_monitor
    
    logger.info("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ GPU Worker Service...")
    
    try:
        # Initialize components
        file_handler = FileHandler()
        gpu_monitor = GPUMonitor()
        upscaler = FluxUpscaler()
        
        # Load models
        await upscaler.load_models()
        
        logger.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
        
        yield
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø©: {e}")
        raise
    finally:
        logger.info("ğŸ”„ Ø¥ÙŠÙ‚Ø§Ù GPU Worker Service...")
        if upscaler:
            await upscaler.cleanup()


# Create FastAPI app
app = FastAPI(
    title="SM_UP GPU Worker",
    description="Ø®Ø¯Ù…Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Flux Dev + LoRA",
    version="1.0.0",
    lifespan=lifespan
)

# Setup monitoring
setup_monitoring(app)


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ø®Ø¯Ù…Ø©"""
    try:
        gpu_info = gpu_monitor.get_gpu_status()
        memory_info = gpu_monitor.get_memory_usage()
        
        return HealthResponse(
            status="healthy",
            gpu_available=gpu_info["available"],
            gpu_memory_used=gpu_info["memory_used"],
            gpu_memory_total=gpu_info["memory_total"],
            system_memory_used=memory_info["used"],
            system_memory_total=memory_info["total"]
        )
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=503, detail="Service unhealthy")


@app.post("/upscale", response_model=UpscaleResponse)
async def upscale_image(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    prompt: str = "high quality, detailed, sharp, professional photography"
):
    """Ø±ÙØ¹ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©"""
    
    if not upscaler:
        raise HTTPException(status_code=503, detail="Upscaler not initialized")
    
    # Validate file
    if not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="File must be an image")
    
    try:
        logger.info(f"ğŸ“¥ Ø§Ø³ØªÙ„Ø§Ù… Ø·Ù„Ø¨ Ù…Ø¹Ø§Ù„Ø¬Ø© ØµÙˆØ±Ø©: {file.filename}")
        
        # Save uploaded file
        input_path = await file_handler.save_upload(file)
        
        # Validate image
        if not await file_handler.validate_image(input_path):
            raise HTTPException(status_code=400, detail="Invalid image file")
        
        # Process image
        result = await upscaler.upscale_image(input_path, prompt)
        
        # Schedule cleanup
        background_tasks.add_task(file_handler.cleanup_temp_files, [input_path])
        
        logger.success(f"âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­: {result.output_path}")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {e}")
        raise HTTPException(status_code=500, detail=f"Processing failed: {str(e)}")


@app.get("/status")
async def get_status():
    """Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©"""
    try:
        return {
            "service": "gpu-worker",
            "status": "running",
            "models_loaded": upscaler.is_loaded if upscaler else False,
            "gpu_status": gpu_monitor.get_detailed_status(),
            "queue_size": 0,  # Ø³ÙŠØªÙ… ØªØ·ÙˆÙŠØ±Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹
            "processed_today": 0  # Ø³ÙŠØªÙ… ØªØ·ÙˆÙŠØ±Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹
        }
    except Exception as e:
        logger.error(f"Status check failed: {e}")
        return {"status": "error", "message": str(e)}


@app.get("/metrics")
async def get_metrics():
    """Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù„Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©"""
    try:
        return {
            "gpu_utilization": gpu_monitor.get_gpu_utilization(),
            "memory_usage": gpu_monitor.get_memory_usage(),
            "temperature": gpu_monitor.get_gpu_temperature(),
            "processing_time_avg": 0,  # Ø³ÙŠØªÙ… ØªØ·ÙˆÙŠØ±Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹
            "success_rate": 100  # Ø³ÙŠØªÙ… ØªØ·ÙˆÙŠØ±Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹
        }
    except Exception as e:
        logger.error(f"Metrics collection failed: {e}")
        return {"error": str(e)}


if __name__ == "__main__":
    logger.info("ğŸ”¥ ØªØ´ØºÙŠÙ„ GPU Worker Service...")
    
    uvicorn.run(
        "app:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=settings.DEBUG,
        log_level="info"
    )
